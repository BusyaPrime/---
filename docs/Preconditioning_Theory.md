# Спектральная Теория Прекондеев (База для пацанов)

Когда мы решаем дискретную СЛАУ $Au = rhs$ (неважно, симметричную или кривую), методы подпространств Крылова (типа нашего PCG - Preconditioned Conjugate Gradient) упираются рогом в спектральное число обусловленности матрицы итераций $\kappa = \lambda_{max} / \lambda_{min}$. Если оно большое — мы приехали, сходимости не будет.

Для классического 5-точечного дискретного Лапласиана на равномерной сетке с шагом $h$, это число улетает в космос со скоростью $O(h^{-2}) \approx O(N)$. Короче, при $N \to 1024^2$ спектральный радиус пробивает потолок, и PCG тупо стагнирует (крутит циклы вхолостую).

## 1. Диагональный (Jacobi) Прекондей (Дешево и сердито)
Самый ленивый маппинг ускорения — это тупо $M^{-1} \approx \text{diag}(A)^{-1}$.
Для нашего неявного стенсила диагональный элемент железобетонно равен сумме внедиагональных весов диффузии плюс неявный фактор времени:
$$ a_{i,i} = 1 + \frac{\Delta t \cdot \alpha}{2} \left[ \frac{2}{\Delta x^2} + \frac{2}{\Delta y^2} \right] $$

Jacobi прекондей жестко нормирует спектр собственных значений вокруг $1.0$. Он круто срезает верхушку $\lambda_{max}$, но абсолютно сливает на низкочастотных (low-frequency) ошибках $\lambda_{min}$. 

## 2. Geometric Multigrid (MG) Прекондей (Тяжелая артиллерия)
Чтобы выйти на трушный $O(1)$ flat scaling (когда время решения вообще не зависит от размера сетки), нам надо заюзать фичу: высокочастотные ошибки (шум) легко давятся стандартными релаксациями (тем же Jacobi), а вот низкочастотные (длинные волны) становятся "высокочастотными" только если мы безжалостно загрубим сетку (coarsen).

Запихиваем MG V-cycle $M^{-1}_{MG}$ прямо внутрь хот-лупа PCG:
1.  **Pre-smooth (Пред-сглаживание)**: Глушим $\lambda_{max}$ (снимаем высокочастотный мусор).
2.  **Restrict (Рестрикция/Сужение)**: Перебрасываем residual (невязку) на более грубую сетку (coarse sub-grid).
3.  **Solve (Решение)**: Считаем ошибку на грубом уровне (где она уже не кажется низкочастотной).
4.  **Prolongate (Пролонгация/Экстраполяция)**: Натягиваем грубую ошибку обратно на мелкоячеистую сетку (fine mesh).
5.  **Post-smooth (Пост-сглаживание)**: Сбриваем высокочастотный мусор, который прилетел из-за интерполяции на шаге 4.

Математики давно пруфнули, что $\kappa(M_{MG}^{-1}A) \le C$ и этому условию вообще пофиг на размер сетки $N$. Спектр собственных значений плющится в блин, и наш PCG превращается в лютый $O(N)$ движок вместо тормозного $O(N^{1.5})$. Это база.
